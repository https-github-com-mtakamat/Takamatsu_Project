{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.10.0'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ドライブ D のボリューム ラベルがありません。\n",
      " ボリューム シリアル番号は 5AB5-9BCD です\n",
      "\n",
      " D:\\Takam\\OctUnet のディレクトリ\n",
      "\n",
      "02/03/2020  10:57 AM    <DIR>          .\n",
      "02/03/2020  10:57 AM    <DIR>          ..\n",
      "02/02/2020  10:59 PM    <DIR>          .ipynb_checkpoints\n",
      "02/03/2020  10:57 AM    <DIR>          data\n",
      "02/03/2020  10:57 AM           165,602 oct_unet.ipynb\n",
      "02/03/2020  02:24 AM       415,234,496 unet_membrane.hdf5\n",
      "               2 個のファイル         415,400,098 バイト\n",
      "               4 個のディレクトリ  1,069,114,523,648 バイトの空き領域\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nOctave UNetの実装\\n\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Octave UNetの実装\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.optimizers import *\n",
    "\n",
    "__all__ = ['OctaveConv2D', 'octave_conv_2d']\n",
    "\n",
    "\n",
    "class OctaveConv2D(Layer):\n",
    "    \"\"\"Octave convolutions.\n",
    "    # Arguments\n",
    "        octave: The division of the spatial dimensions by a power of 2.\n",
    "        ratio_out: The ratio of filters for lower spatial resolution.\n",
    "    # References\n",
    "        - [Drop an Octave: Reducing Spatial Redundancy in Convolutional Neural Networks with Octave Convolution]\n",
    "          (https://arxiv.org/pdf/1904.05049.pdf)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 filters,\n",
    "                 kernel_size=(3,3),\n",
    "                 octave=2,\n",
    "                 ratio_out=0.125,\n",
    "                 strides=(1, 1),\n",
    "                 data_format=None,\n",
    "                 dilation_rate=(1, 1),\n",
    "                 activation=None,\n",
    "                 use_bias=False,\n",
    "                 use_transpose=False,\n",
    "                 kernel_initializer='he_normal',\n",
    "                 bias_initializer='zeros',\n",
    "                 kernel_regularizer=None,\n",
    "                 bias_regularizer=None,\n",
    "                 activity_regularizer=None,\n",
    "                 kernel_constraint=None,\n",
    "                 bias_constraint=None,\n",
    "                 **kwargs):\n",
    "        super(OctaveConv2D, self).__init__(**kwargs)\n",
    "        self.filters = filters\n",
    "        self.kernel_size = kernel_size\n",
    "        self.octave = octave\n",
    "        self.ratio_out = ratio_out\n",
    "        self.strides = strides\n",
    "        self.data_format = data_format\n",
    "        self.dilation_rate = dilation_rate\n",
    "        self.use_bias = use_bias\n",
    "        self.use_transpose = use_transpose\n",
    "        self.kernel_initializer = kernel_initializer\n",
    "        self.bias_initializer = bias_initializer\n",
    "        self.kernel_regularizer = kernel_regularizer\n",
    "        self.bias_regularizer = bias_regularizer\n",
    "        self.activity_regularizer = activity_regularizer\n",
    "        self.kernel_constraint = kernel_constraint\n",
    "        self.bias_constraint = bias_constraint\n",
    "\n",
    "        self.filters_low = int(filters * self.ratio_out)\n",
    "        self.filters_high = filters - self.filters_low\n",
    "\n",
    "        self.conv_high_to_high, self.conv_low_to_high = None, None\n",
    "        if self.use_transpose:\n",
    "          if self.filters_high > 0:\n",
    "              self.conv_high_to_high = self._init_transconv(self.filters_high, name='{}-Trans-Conv2D-HH'.format(self.name))\n",
    "              self.conv_low_to_high = self._init_transconv(self.filters_high, name='{}-Conv2D-LH'.format(self.name))\n",
    "          self.conv_low_to_low, self.conv_high_to_low = None, None\n",
    "          if self.filters_low > 0:\n",
    "              self.conv_low_to_low = self._init_transconv(self.filters_low, name='{}-Trans-Conv2D-HL'.format(self.name))\n",
    "              self.conv_high_to_low = self._init_transconv(self.filters_low, name='{}-Trans-Conv2D-LL'.format(self.name))\n",
    "          self.pooling = AveragePooling2D(\n",
    "              pool_size=self.octave,\n",
    "              padding='valid',\n",
    "              data_format=data_format,\n",
    "              name='{}-AveragePooling2D'.format(self.name),\n",
    "          )\n",
    "          self.up_sampling = UpSampling2D(\n",
    "              size=self.octave,\n",
    "              data_format=data_format,\n",
    "              name='{}-UpSampling2D'.format(self.name)\n",
    "          )\n",
    "        else:\n",
    "          if self.filters_high > 0:\n",
    "              self.conv_high_to_high = self._init_conv(self.filters_high, name='{}-Conv2D-HH'.format(self.name))\n",
    "              self.conv_low_to_high = self._init_conv(self.filters_high, name='{}-Conv2D-LH'.format(self.name))\n",
    "          self.conv_low_to_low, self.conv_high_to_low = None, None\n",
    "          if self.filters_low > 0:\n",
    "              self.conv_low_to_low = self._init_conv(self.filters_low, name='{}-Conv2D-HL'.format(self.name))\n",
    "              self.conv_high_to_low = self._init_conv(self.filters_low, name='{}-Conv2D-LL'.format(self.name))\n",
    "          self.pooling = AveragePooling2D(\n",
    "              pool_size=self.octave,\n",
    "              padding='valid',\n",
    "              data_format=data_format,\n",
    "              name='{}-AveragePooling2D'.format(self.name),\n",
    "          )\n",
    "          self.up_sampling = UpSampling2D(\n",
    "              size=self.octave,\n",
    "              data_format=data_format,\n",
    "              name='{}-UpSampling2D'.format(self.name)\n",
    "          )\n",
    "    def _init_transconv(self, filters, name):\n",
    "        return Conv2DTranspose(\n",
    "            filters=filters,\n",
    "            kernel_size=self.kernel_size,\n",
    "            strides=self.strides,\n",
    "            padding='same',\n",
    "            data_format=self.data_format,\n",
    "            dilation_rate=self.dilation_rate,\n",
    "            use_bias=self.use_bias,\n",
    "            kernel_initializer=self.kernel_initializer,\n",
    "            bias_initializer=self.bias_initializer,\n",
    "            kernel_regularizer=self.kernel_regularizer,\n",
    "            bias_regularizer=self.bias_regularizer,\n",
    "            activity_regularizer=self.activity_regularizer,\n",
    "            kernel_constraint=self.kernel_constraint,\n",
    "            bias_constraint=self.bias_constraint,\n",
    "            name=name,\n",
    "        )\n",
    "\n",
    "    def _init_conv(self, filters, name):\n",
    "        return Conv2D(\n",
    "            filters=filters,\n",
    "            kernel_size=self.kernel_size,\n",
    "            strides=self.strides,\n",
    "            padding='same',\n",
    "            data_format=self.data_format,\n",
    "            dilation_rate=self.dilation_rate,\n",
    "            use_bias=self.use_bias,\n",
    "            kernel_initializer=self.kernel_initializer,\n",
    "            bias_initializer=self.bias_initializer,\n",
    "            kernel_regularizer=self.kernel_regularizer,\n",
    "            bias_regularizer=self.bias_regularizer,\n",
    "            activity_regularizer=self.activity_regularizer,\n",
    "            kernel_constraint=self.kernel_constraint,\n",
    "            bias_constraint=self.bias_constraint,\n",
    "            name=name,\n",
    "        )\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        if isinstance(input_shape, list):\n",
    "            input_shape_high, input_shape_low = input_shape\n",
    "        else:\n",
    "            input_shape_high, input_shape_low = input_shape, None\n",
    "        if self.data_format == 'channels_first':\n",
    "            channel_axis, rows_axis, cols_axis = 1, 2, 3\n",
    "        else:\n",
    "            rows_axis, cols_axis, channel_axis = 1, 2, 3\n",
    "        if input_shape_high[channel_axis] is None:\n",
    "            raise ValueError('The channel dimension of the higher spatial inputs '\n",
    "                             'should be defined. Found `None`.')\n",
    "        if input_shape_low is not None and input_shape_low[channel_axis] is None:\n",
    "            raise ValueError('The channel dimension of the lower spatial inputs '\n",
    "                             'should be defined. Found `None`.')\n",
    "        if input_shape_high[rows_axis] is not None and input_shape_high[rows_axis] % self.octave != 0 or \\\n",
    "           input_shape_high[cols_axis] is not None and input_shape_high[cols_axis] % self.octave != 0:\n",
    "            raise ValueError('The rows and columns of the higher spatial inputs should be divisible by the octave. '\n",
    "                             'Found {} and {}.'.format(input_shape_high, self.octave))\n",
    "        if input_shape_low is None:\n",
    "            self.conv_low_to_high, self.conv_low_to_low = None, None\n",
    "\n",
    "        if self.conv_high_to_high is not None:\n",
    "            with K.name_scope(self.conv_high_to_high.name):\n",
    "                self.conv_high_to_high.build(input_shape_high)\n",
    "        if self.conv_low_to_high is not None:\n",
    "            with K.name_scope(self.conv_low_to_high.name):\n",
    "                self.conv_low_to_high.build(input_shape_low)\n",
    "        if self.conv_high_to_low is not None:\n",
    "            with K.name_scope(self.conv_high_to_low.name):\n",
    "                self.conv_high_to_low.build(input_shape_high)\n",
    "        if self.conv_low_to_low is not None:\n",
    "            with K.name_scope(self.conv_low_to_low.name):\n",
    "                self.conv_low_to_low.build(input_shape_low)\n",
    "        super(OctaveConv2D, self).build(input_shape)\n",
    "\n",
    "    @property\n",
    "    def trainable_weights(self):\n",
    "        weights = []\n",
    "        if self.conv_high_to_high is not None:\n",
    "            weights += self.conv_high_to_high.trainable_weights\n",
    "        if self.conv_low_to_high is not None:\n",
    "            weights += self.conv_low_to_high.trainable_weights\n",
    "        if self.conv_high_to_low is not None:\n",
    "            weights += self.conv_high_to_low.trainable_weights\n",
    "        if self.conv_low_to_low is not None:\n",
    "            weights += self.conv_low_to_low.trainable_weights\n",
    "        return weights\n",
    "\n",
    "    @property\n",
    "    def non_trainable_weights(self):\n",
    "        weights = []\n",
    "        if self.conv_high_to_high is not None:\n",
    "            weights += self.conv_high_to_high.non_trainable_weights\n",
    "        if self.conv_low_to_high is not None:\n",
    "            weights += self.conv_low_to_high.non_trainable_weights\n",
    "        if self.conv_high_to_low is not None:\n",
    "            weights += self.conv_high_to_low.non_trainable_weights\n",
    "        if self.conv_low_to_low is not None:\n",
    "            weights += self.conv_low_to_low.non_trainable_weights\n",
    "        return weights\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        if isinstance(input_shape, list):\n",
    "            input_shape_high, input_shape_low = input_shape\n",
    "        else:\n",
    "            input_shape_high, input_shape_low = input_shape, None\n",
    "\n",
    "        output_shape_high = None\n",
    "        if self.filters_high > 0:\n",
    "            output_shape_high = self.conv_high_to_high.compute_output_shape(input_shape_high)\n",
    "        output_shape_low = None\n",
    "        if self.filters_low > 0:\n",
    "            output_shape_low = self.conv_high_to_low.compute_output_shape(\n",
    "                self.pooling.compute_output_shape(input_shape_high),\n",
    "            )\n",
    "\n",
    "        if self.filters_low == 0:\n",
    "            return output_shape_high\n",
    "        if self.filters_high == 0:\n",
    "            return output_shape_low\n",
    "        return [output_shape_high, output_shape_low]\n",
    "\n",
    "    def call(self, inputs, **kwargs):\n",
    "        if isinstance(inputs, list):\n",
    "            inputs_high, inputs_low = inputs\n",
    "        else:\n",
    "            inputs_high, inputs_low = inputs, None\n",
    "\n",
    "        outputs_high_to_high, outputs_low_to_high = 0.0, 0.0\n",
    "        if self.use_transpose:\n",
    "          if self.conv_high_to_high is not None:\n",
    "              outputs_high_to_high = self.conv_high_to_high(inputs_high)\n",
    "          if self.conv_low_to_high is not None:\n",
    "              outputs_low_to_high = self.up_sampling(self.conv_low_to_high(inputs_low))\n",
    "          outputs_high = outputs_high_to_high + outputs_low_to_high\n",
    "\n",
    "          outputs_low_to_low, outputs_high_to_low = 0.0, 0.0\n",
    "          if self.conv_low_to_low is not None:\n",
    "              outputs_low_to_low = self.conv_low_to_low(inputs_low)\n",
    "          if self.conv_high_to_low is not None:\n",
    "              outputs_high_to_low = self.pooling(self.conv_high_to_low(inputs_high))\n",
    "          outputs_low = outputs_low_to_low + outputs_high_to_low\n",
    "\n",
    "          if self.filters_low == 0:\n",
    "              return outputs_high\n",
    "          if self.filters_high == 0:\n",
    "              return outputs_low\n",
    "        else:\n",
    "          if self.conv_high_to_high is not None:\n",
    "              outputs_high_to_high = self.conv_high_to_high(inputs_high)\n",
    "          if self.conv_low_to_high is not None:\n",
    "              outputs_low_to_high = self.up_sampling(self.conv_low_to_high(inputs_low))\n",
    "          outputs_high = outputs_high_to_high + outputs_low_to_high\n",
    "\n",
    "          outputs_low_to_low, outputs_high_to_low = 0.0, 0.0\n",
    "          if self.conv_low_to_low is not None:\n",
    "              outputs_low_to_low = self.conv_low_to_low(inputs_low)\n",
    "          if self.conv_high_to_low is not None:\n",
    "              outputs_high_to_low = self.conv_high_to_low(self.pooling(inputs_high))\n",
    "          outputs_low = outputs_low_to_low + outputs_high_to_low\n",
    "\n",
    "          if self.filters_low == 0:\n",
    "              return outputs_high\n",
    "          if self.filters_high == 0:\n",
    "              return outputs_low\n",
    "        return [outputs_high, outputs_low]\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {\n",
    "            'filters': self.filters,\n",
    "            'kernel_size': self.kernel_size,\n",
    "            'octave': self.octave,\n",
    "            'ratio_out': self.ratio_out,\n",
    "            'strides': self.strides,\n",
    "            'data_format': self.data_format,\n",
    "            'dilation_rate': self.dilation_rate,\n",
    "            'use_bias': self.use_bias,\n",
    "            'kernel_initializer': self.kernel_initializer,\n",
    "            'bias_initializer': self.bias_initializer,\n",
    "            'kernel_regularizer': self.kernel_regularizer,\n",
    "            'bias_regularizer': self.bias_regularizer,\n",
    "            'activity_regularizer': self.activity_regularizer,\n",
    "            'kernel_constraint': self.kernel_constraint,\n",
    "            'bias_constraint': self.bias_constraint\n",
    "        }\n",
    "        base_config = super(OctaveConv2D, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model code all in this cell\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import collections\n",
    "import math\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "#from keras_radam.training import RAdamOptimizer\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "#from keras_octave_conv import OctaveConv2D\n",
    "      \n",
    "      \n",
    "def unet(pretrained_weights = None,input_size = (256,256,3)):\n",
    "    inputs = Input(input_size)\n",
    "    # downsampling for lower\n",
    "    low = layers.AveragePooling2D(2)(inputs)\n",
    "    high1, low1 = OctaveConv2D(64)([inputs,low])\n",
    "    high1 = layers.BatchNormalization()(high1)\n",
    "    high1 = layers.Activation(\"relu\")(high1)\n",
    "    low1 = layers.BatchNormalization()(low1)\n",
    "    low1 = layers.Activation(\"relu\")(low1)\n",
    "    high1, low1 = OctaveConv2D(64)([high1, low1])\n",
    "    high1 = layers.BatchNormalization()(high1)\n",
    "    high1 = layers.Activation(\"relu\")(high1)\n",
    "    low1 = layers.BatchNormalization()(low1)\n",
    "    low1 = layers.Activation(\"relu\")(low1)\n",
    "    pool1high = layers.MaxPooling2D(2)(high1)\n",
    "    pool1low = layers.MaxPooling2D(2)(low1)\n",
    "    \n",
    "    high2, low2 = OctaveConv2D(128)([pool1high,pool1low])\n",
    "    high2 = layers.BatchNormalization()(high2)\n",
    "    high2 = layers.Activation(\"relu\")(high2)\n",
    "    low2 = layers.BatchNormalization()(low2)\n",
    "    low2 = layers.Activation(\"relu\")(low2)\n",
    "    high2, low2 = OctaveConv2D(128)([high2, low2])\n",
    "    high2 = layers.BatchNormalization()(high2)\n",
    "    high2 = layers.Activation(\"relu\")(high2)\n",
    "    low2 = layers.BatchNormalization()(low2)\n",
    "    low2 = layers.Activation(\"relu\")(low2)\n",
    "    pool2high = layers.MaxPooling2D(2)(high2)\n",
    "    pool2low = layers.MaxPooling2D(2)(low2)\n",
    "    \n",
    "    high3, low3 = OctaveConv2D(256)([pool2high,pool2low])\n",
    "    high3 = layers.BatchNormalization()(high3)\n",
    "    high3 = layers.Activation(\"relu\")(high3)\n",
    "    low3 = layers.BatchNormalization()(low3)\n",
    "    low3 = layers.Activation(\"relu\")(low3)\n",
    "    high3, low3 = OctaveConv2D(256)([high3, low3])\n",
    "    high3 = layers.BatchNormalization()(high3)\n",
    "    high3 = layers.Activation(\"relu\")(high3)\n",
    "    low3 = layers.BatchNormalization()(low3)\n",
    "    low3 = layers.Activation(\"relu\")(low3)\n",
    "    pool3high = layers.MaxPooling2D(2)(high3)\n",
    "    pool3low = layers.MaxPooling2D(2)(low3)\n",
    "    \n",
    "    high4, low4 = OctaveConv2D(512)([pool3high,pool3low])\n",
    "    high4 = layers.BatchNormalization()(high4)\n",
    "    high4 = layers.Activation(\"relu\")(high4)\n",
    "    low4 = layers.BatchNormalization()(low4)\n",
    "    low4 = layers.Activation(\"relu\")(low4)\n",
    "    high4, low4 = OctaveConv2D(512)([high4, low4])\n",
    "    high4 = layers.BatchNormalization()(high4)\n",
    "    high4 = layers.Activation(\"relu\")(high4)\n",
    "    low4 = layers.BatchNormalization()(low4)\n",
    "    low4 = layers.Activation(\"relu\")(low4)\n",
    "    pool4high = layers.MaxPooling2D(2)(high4)\n",
    "    pool4low = layers.MaxPooling2D(2)(low4)\n",
    "\n",
    "    high5, low5 = OctaveConv2D(1024)([pool4high, pool4low])\n",
    "    high5 = layers.BatchNormalization()(high5)\n",
    "    high5 = layers.Activation(\"relu\")(high5)\n",
    "    low5 = layers.BatchNormalization()(low5)\n",
    "    low5 = layers.Activation(\"relu\")(low5)\n",
    "    high5 = Dropout(0.4)(high5)\n",
    "    low5 = Dropout(0.4)(low5)\n",
    "    high5, low5 = OctaveConv2D(1024)([high5, low5])\n",
    "    high5 = layers.BatchNormalization()(high5)\n",
    "    high5 = layers.Activation(\"relu\")(high5)\n",
    "    low5 = layers.BatchNormalization()(low5)\n",
    "    low5 = layers.Activation(\"relu\")(low5)\n",
    "    high5 = Dropout(0.4)(high5)\n",
    "    low5 = Dropout(0.4)(low5)\n",
    "    \n",
    "    uphigh6, uplow6 = OctaveConv2D(512, use_transpose=True, strides=(2,2))([high5,low5])\n",
    "    uphigh6 = layers.BatchNormalization()(uphigh6)\n",
    "    uphigh6 = layers.Activation(\"relu\")(uphigh6)\n",
    "    uplow6 = layers.BatchNormalization()(uplow6)\n",
    "    uplow6 = layers.Activation(\"relu\")(uplow6)\n",
    "    merge6high = concatenate([high4,uphigh6], axis = 3)\n",
    "    merge6low = concatenate([low4,uplow6], axis = 3)\n",
    "    high6, low6 = OctaveConv2D(512)([merge6high,merge6low])\n",
    "    high6 = layers.BatchNormalization()(high6)\n",
    "    high6 = layers.Activation(\"relu\")(high6)\n",
    "    low6 = layers.BatchNormalization()(low6)\n",
    "    low6 = layers.Activation(\"relu\")(low6)\n",
    "    high6, low6 = OctaveConv2D(512)([high6, low6])\n",
    "    high6 = layers.BatchNormalization()(high6)\n",
    "    high6 = layers.Activation(\"relu\")(high6)\n",
    "    low6 = layers.BatchNormalization()(low6)\n",
    "    low6 = layers.Activation(\"relu\")(low6)\n",
    "\n",
    "\n",
    "    uphigh7, uplow7 = OctaveConv2D(256, use_transpose=True, strides=(2,2))([high6, low6])\n",
    "    uphigh7 = layers.BatchNormalization()(uphigh7)\n",
    "    uphigh7 = layers.Activation(\"relu\")(uphigh7)\n",
    "    uplow7 = layers.BatchNormalization()(uplow7)\n",
    "    uplow7 = layers.Activation(\"relu\")(uplow7)\n",
    "    merge7high = concatenate([high3,uphigh7], axis = 3)\n",
    "    merge7low = concatenate([low3,uplow7], axis = 3)\n",
    "    high7, low7 = OctaveConv2D(256)([merge7high, merge7low])\n",
    "    high7 = layers.BatchNormalization()(high7)\n",
    "    high7 = layers.Activation(\"relu\")(high7)\n",
    "    low7 = layers.BatchNormalization()(low7)\n",
    "    low7 = layers.Activation(\"relu\")(low7)\n",
    "    high7, low7 = OctaveConv2D(256)([high7, low7])\n",
    "    high7 = layers.BatchNormalization()(high7)\n",
    "    high7 = layers.Activation(\"relu\")(high7)\n",
    "    low7 = layers.BatchNormalization()(low7)\n",
    "    low7 = layers.Activation(\"relu\")(low7)\n",
    "\n",
    "    uphigh8, uplow8 = OctaveConv2D(128, use_transpose=True, strides=(2,2))([high7, low7])\n",
    "    uphigh8 = layers.BatchNormalization()(uphigh8)\n",
    "    uphigh8 = layers.Activation(\"relu\")(uphigh8)\n",
    "    uplow8 = layers.BatchNormalization()(uplow8)\n",
    "    uplow8 = layers.Activation(\"relu\")(uplow8)\n",
    "    merge8high = concatenate([high2,uphigh8], axis = 3)\n",
    "    merge8low = concatenate([low2,uplow8], axis = 3)\n",
    "    high8, low8 = OctaveConv2D(128)([merge8high, merge8low])\n",
    "    high8 = layers.BatchNormalization()(high8)\n",
    "    high8 = layers.Activation(\"relu\")(high8)\n",
    "    low8 = layers.BatchNormalization()(low8)\n",
    "    low8 = layers.Activation(\"relu\")(low8)\n",
    "    high8, low8 = OctaveConv2D(128)([high8, low8])\n",
    "    high8 = layers.BatchNormalization()(high8)\n",
    "    high8 = layers.Activation(\"relu\")(high8)\n",
    "    low8 = layers.BatchNormalization()(low8)\n",
    "    low8 = layers.Activation(\"relu\")(low8)\n",
    "\n",
    "    uphigh9, uplow9 = OctaveConv2D(64, use_transpose=True, strides=(2,2))([high8, low8])\n",
    "    uphigh9 = layers.BatchNormalization()(uphigh9)\n",
    "    uphigh9 = layers.Activation(\"relu\")(uphigh9)\n",
    "    uplow9 = layers.BatchNormalization()(uplow9)\n",
    "    uplow9 = layers.Activation(\"relu\")(uplow9)\n",
    "    merge9high = concatenate([high1,uphigh9], axis = 3)\n",
    "    merge9low = concatenate([low1,uplow9], axis = 3)\n",
    "    high9, low9 = OctaveConv2D(64)([merge9high, merge9low])\n",
    "    high9 = layers.BatchNormalization()(high9)\n",
    "    high9 = layers.Activation(\"relu\")(high9)\n",
    "    low9 = layers.BatchNormalization()(low9)\n",
    "    low9 = layers.Activation(\"relu\")(low9)\n",
    "    high9, low9 = OctaveConv2D(64)([high9, low9])\n",
    "    high9 = layers.BatchNormalization()(high9)\n",
    "    high9 = layers.Activation(\"relu\")(high9)\n",
    "    low9 = layers.BatchNormalization()(low9)\n",
    "    low9 = layers.Activation(\"relu\")(low9)\n",
    "    conv9 = OctaveConv2D(32, ratio_out=0.0)([high9, low9])\n",
    "    conv9 = layers.Activation(\"sigmoid\")(conv9)\n",
    "    conv10 = layers.Conv2D(1, 1, activation = 'sigmoid')(conv9)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=conv10)\n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    model.compile(optimizer = Adam(lr=1e-4), loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "    if(pretrained_weights):\n",
    "    \tmodel.load_weights(pretrained_weights)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nResUNetの実装\\n\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "ResUNetの実装\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ResUNet\n",
    "import collections\n",
    "import math\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "#from keras_radam.training import RAdamOptimizer\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "\n",
    "def bn_act(x, act=True):\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    if act == True:\n",
    "        x = layers.Activation(\"relu\")(x)\n",
    "    return x\n",
    "\n",
    "def conv_block(x, filters, kernel_size=(3, 3), padding=\"same\", strides=1):\n",
    "    conv = bn_act(x)\n",
    "    conv = layers.Conv2D(filters, kernel_size, padding=padding, strides=strides)(conv)\n",
    "    return conv\n",
    "\n",
    "def stem(x, filters, kernel_size=(3, 3), padding=\"same\", strides=1):\n",
    "    conv = layers.Conv2D(filters, kernel_size, padding=padding, strides=strides)(x)\n",
    "    conv = conv_block(conv, filters, kernel_size=kernel_size, padding=padding, strides=strides)\n",
    "    \n",
    "    shortcut = layers.Conv2D(filters, kernel_size=(1, 1), padding=padding, strides=strides)(x)\n",
    "    shortcut = bn_act(shortcut, act=False)\n",
    "    \n",
    "    output = layers.Add()([conv, shortcut])\n",
    "    return output\n",
    "\n",
    "def residual_block(x, filters, kernel_size=(3, 3), padding=\"same\", strides=1):\n",
    "    res = conv_block(x, filters, kernel_size=kernel_size, padding=padding, strides=strides)\n",
    "    res = conv_block(res, filters, kernel_size=kernel_size, padding=padding, strides=1)\n",
    "    \n",
    "    shortcut = layers.Conv2D(filters, kernel_size=(1, 1), padding=padding, strides=strides)(x)\n",
    "    shortcut = bn_act(shortcut, act=False)\n",
    "    \n",
    "    output = layers.Add()([shortcut, res])\n",
    "    return output\n",
    "\n",
    "def upsample_concat_block(x, xskip):\n",
    "    u = layers.UpSampling2D((2, 2))(x)\n",
    "    c = layers.Concatenate()([u, xskip])\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size=256\n",
    "\n",
    "def ResUNet():\n",
    "    f = [16, 32, 64, 128, 256]\n",
    "    inputs = layers.Input((image_size, image_size, 3))\n",
    "    \n",
    "    ## Encoder\n",
    "    e0 = inputs\n",
    "    e1 = stem(e0, f[0])\n",
    "    e2 = residual_block(e1, f[1], strides=2)\n",
    "    e3 = residual_block(e2, f[2], strides=2)\n",
    "    e4 = residual_block(e3, f[3], strides=2)\n",
    "    e5 = residual_block(e4, f[4], strides=2)\n",
    "    \n",
    "    ## Bridge\n",
    "    b0 = conv_block(e5, f[4], strides=1)\n",
    "    b1 = conv_block(b0, f[4], strides=1)\n",
    "    \n",
    "    ## Decoder\n",
    "    u1 = upsample_concat_block(b1, e4)\n",
    "    d1 = residual_block(u1, f[4])\n",
    "    \n",
    "    u2 = upsample_concat_block(d1, e3)\n",
    "    d2 = residual_block(u2, f[3])\n",
    "    \n",
    "    u3 = upsample_concat_block(d2, e2)\n",
    "    d3 = residual_block(u3, f[2])\n",
    "    \n",
    "    u4 = upsample_concat_block(d3, e1)\n",
    "    d4 = residual_block(u4, f[1])\n",
    "    \n",
    "    outputs = layers.Conv2D(1, (1, 1), padding=\"same\", activation=\"sigmoid\")(d4)\n",
    "    model = Model(inputs, outputs)\n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    model.compile(optimizer = Adam(lr=1e-4), loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainGenerator(batch_size,train_path,image_folder,mask_folder,aug_dict,image_color_mode = \"rgb\",\n",
    "                    mask_color_mode = \"grayscale\",image_save_prefix  = \"image\",mask_save_prefix  = \"mask\",\n",
    "                    flag_multi_class = False,num_class = 2,save_to_dir = None,target_size = (256,256),seed = 1):\n",
    "    '''\n",
    "    can generate image and mask at the same time\n",
    "    use the same seed for image_datagen and mask_datagen to ensure the transformation for image and mask is the same\n",
    "    if you want to visualize the results of generator, set save_to_dir = \"your path\"\n",
    "    '''\n",
    "    image_datagen = ImageDataGenerator(**aug_dict)\n",
    "    mask_datagen = ImageDataGenerator(**aug_dict)\n",
    "    image_generator = image_datagen.flow_from_directory(\n",
    "        train_path,\n",
    "        classes = [image_folder],\n",
    "        class_mode = None,\n",
    "        color_mode = image_color_mode,\n",
    "        target_size = target_size,\n",
    "        batch_size = batch_size,\n",
    "        save_to_dir = save_to_dir,\n",
    "        save_prefix  = image_save_prefix,\n",
    "        seed = seed)\n",
    "    mask_generator = mask_datagen.flow_from_directory(\n",
    "        train_path,\n",
    "        classes = [mask_folder],\n",
    "        class_mode = None,\n",
    "        color_mode = mask_color_mode,\n",
    "        target_size = target_size,\n",
    "        batch_size = batch_size,\n",
    "        save_to_dir = save_to_dir,\n",
    "        save_prefix  = mask_save_prefix,\n",
    "        seed = seed)\n",
    "    train_generator = zip(image_generator, mask_generator)\n",
    "    for (img,mask) in train_generator:\n",
    "        img,mask = adjustData(img,mask,flag_multi_class,num_class)\n",
    "        yield (img,mask)\n",
    "        \n",
    "def adjustData(img,mask,flag_multi_class,num_class):\n",
    "    if(flag_multi_class):\n",
    "        img = img / 255\n",
    "        mask = mask[:,:,:,0] if(len(mask.shape) == 4) else mask[:,:,0]\n",
    "        new_mask = np.zeros(mask.shape + (num_class,))\n",
    "        for i in range(num_class):\n",
    "            #for one pixel in the image, find the class in mask and convert it into one-hot vector\n",
    "            #index = np.where(mask == i)\n",
    "            #index_mask = (index[0],index[1],index[2],np.zeros(len(index[0]),dtype = np.int64) + i) if (len(mask.shape) == 4) else (index[0],index[1],np.zeros(len(index[0]),dtype = np.int64) + i)\n",
    "            #new_mask[index_mask] = 1\n",
    "            new_mask[mask == i,i] = 1\n",
    "        new_mask = np.reshape(new_mask,(new_mask.shape[0],new_mask.shape[1]*new_mask.shape[2],new_mask.shape[3])) if flag_multi_class else np.reshape(new_mask,(new_mask.shape[0]*new_mask.shape[1],new_mask.shape[2]))\n",
    "        mask = new_mask\n",
    "    elif(np.max(img) > 1):\n",
    "        img = img / 255\n",
    "        mask = mask /255\n",
    "        mask[mask > 0.5] = 1\n",
    "        mask[mask <= 0.5] = 0\n",
    "    return (img,mask)\n",
    "  \n",
    "def geneTrainNpy(image_path,mask_path,flag_multi_class = False,num_class = 2,image_prefix = \"image\",mask_prefix = \"mask\",image_as_gray = True,mask_as_gray = True):\n",
    "    image_name_arr = glob.glob(os.path.join(image_path,\"%s*.jpg\"%image_prefix))\n",
    "    image_arr = []\n",
    "    mask_arr = []\n",
    "    for index,item in enumerate(image_name_arr):\n",
    "        img = io.imread(item,as_gray = image_as_gray)\n",
    "        img = np.reshape(img,img.shape + (1,)) if image_as_gray else img\n",
    "        mask = io.imread(item.replace(image_path,mask_path).replace(image_prefix,mask_prefix),as_gray = mask_as_gray)\n",
    "        mask = np.reshape(mask,mask.shape + (1,)) if mask_as_gray else mask\n",
    "        img,mask = adjustData(img,mask,flag_multi_class,num_class)\n",
    "        image_arr.append(img)\n",
    "        mask_arr.append(mask)\n",
    "    image_arr = np.array(image_arr)\n",
    "    mask_arr = np.array(mask_arr)\n",
    "    return image_arr,mask_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            (None, 256, 256, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 256, 256, 16) 448         input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_160 (BatchN (None, 256, 256, 16) 64          conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_154 (Activation)     (None, 256, 256, 16) 0           batch_normalization_160[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 256, 256, 16) 64          input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 256, 256, 16) 2320        activation_154[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_161 (BatchN (None, 256, 256, 16) 64          conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 256, 256, 16) 0           conv2d_34[0][0]                  \n",
      "                                                                 batch_normalization_161[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_162 (BatchN (None, 256, 256, 16) 64          add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_155 (Activation)     (None, 256, 256, 16) 0           batch_normalization_162[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 128, 128, 32) 4640        activation_155[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_163 (BatchN (None, 128, 128, 32) 128         conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 128, 128, 32) 544         add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_156 (Activation)     (None, 128, 128, 32) 0           batch_normalization_163[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_164 (BatchN (None, 128, 128, 32) 128         conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 128, 128, 32) 9248        activation_156[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 128, 128, 32) 0           batch_normalization_164[0][0]    \n",
      "                                                                 conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_165 (BatchN (None, 128, 128, 32) 128         add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_157 (Activation)     (None, 128, 128, 32) 0           batch_normalization_165[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 64, 64, 64)   18496       activation_157[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_166 (BatchN (None, 64, 64, 64)   256         conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 64, 64, 64)   2112        add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_158 (Activation)     (None, 64, 64, 64)   0           batch_normalization_166[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_167 (BatchN (None, 64, 64, 64)   256         conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 64, 64, 64)   36928       activation_158[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 64, 64, 64)   0           batch_normalization_167[0][0]    \n",
      "                                                                 conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_168 (BatchN (None, 64, 64, 64)   256         add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_159 (Activation)     (None, 64, 64, 64)   0           batch_normalization_168[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 32, 32, 128)  73856       activation_159[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_169 (BatchN (None, 32, 32, 128)  512         conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 32, 32, 128)  8320        add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_160 (Activation)     (None, 32, 32, 128)  0           batch_normalization_169[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_170 (BatchN (None, 32, 32, 128)  512         conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 32, 32, 128)  147584      activation_160[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 32, 32, 128)  0           batch_normalization_170[0][0]    \n",
      "                                                                 conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_171 (BatchN (None, 32, 32, 128)  512         add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_161 (Activation)     (None, 32, 32, 128)  0           batch_normalization_171[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 16, 16, 256)  295168      activation_161[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_172 (BatchN (None, 16, 16, 256)  1024        conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 16, 16, 256)  33024       add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_162 (Activation)     (None, 16, 16, 256)  0           batch_normalization_172[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_173 (BatchN (None, 16, 16, 256)  1024        conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 16, 16, 256)  590080      activation_162[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 16, 16, 256)  0           batch_normalization_173[0][0]    \n",
      "                                                                 conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_174 (BatchN (None, 16, 16, 256)  1024        add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_163 (Activation)     (None, 16, 16, 256)  0           batch_normalization_174[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 16, 16, 256)  590080      activation_163[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_175 (BatchN (None, 16, 16, 256)  1024        conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_164 (Activation)     (None, 16, 16, 256)  0           batch_normalization_175[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 16, 16, 256)  590080      activation_164[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2D)  (None, 32, 32, 256)  0           conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_28 (Concatenate)    (None, 32, 32, 384)  0           up_sampling2d_4[0][0]            \n",
      "                                                                 add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_176 (BatchN (None, 32, 32, 384)  1536        concatenate_28[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_165 (Activation)     (None, 32, 32, 384)  0           batch_normalization_176[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 32, 32, 256)  884992      activation_165[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_177 (BatchN (None, 32, 32, 256)  1024        conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 32, 32, 256)  98560       concatenate_28[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_166 (Activation)     (None, 32, 32, 256)  0           batch_normalization_177[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_178 (BatchN (None, 32, 32, 256)  1024        conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 32, 32, 256)  590080      activation_166[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 32, 32, 256)  0           batch_normalization_178[0][0]    \n",
      "                                                                 conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_5 (UpSampling2D)  (None, 64, 64, 256)  0           add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_29 (Concatenate)    (None, 64, 64, 320)  0           up_sampling2d_5[0][0]            \n",
      "                                                                 add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_179 (BatchN (None, 64, 64, 320)  1280        concatenate_29[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_167 (Activation)     (None, 64, 64, 320)  0           batch_normalization_179[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 64, 64, 128)  368768      activation_167[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_180 (BatchN (None, 64, 64, 128)  512         conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 64, 64, 128)  41088       concatenate_29[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_168 (Activation)     (None, 64, 64, 128)  0           batch_normalization_180[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_181 (BatchN (None, 64, 64, 128)  512         conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 64, 64, 128)  147584      activation_168[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 64, 64, 128)  0           batch_normalization_181[0][0]    \n",
      "                                                                 conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_6 (UpSampling2D)  (None, 128, 128, 128 0           add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_30 (Concatenate)    (None, 128, 128, 160 0           up_sampling2d_6[0][0]            \n",
      "                                                                 add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_182 (BatchN (None, 128, 128, 160 640         concatenate_30[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_169 (Activation)     (None, 128, 128, 160 0           batch_normalization_182[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 128, 128, 64) 92224       activation_169[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_183 (BatchN (None, 128, 128, 64) 256         conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 128, 128, 64) 10304       concatenate_30[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_170 (Activation)     (None, 128, 128, 64) 0           batch_normalization_183[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_184 (BatchN (None, 128, 128, 64) 256         conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 128, 128, 64) 36928       activation_170[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 128, 128, 64) 0           batch_normalization_184[0][0]    \n",
      "                                                                 conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_7 (UpSampling2D)  (None, 256, 256, 64) 0           add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_31 (Concatenate)    (None, 256, 256, 80) 0           up_sampling2d_7[0][0]            \n",
      "                                                                 add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_185 (BatchN (None, 256, 256, 80) 320         concatenate_31[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_171 (Activation)     (None, 256, 256, 80) 0           batch_normalization_185[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 256, 256, 32) 23072       activation_171[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_186 (BatchN (None, 256, 256, 32) 128         conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 256, 256, 32) 2592        concatenate_31[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_172 (Activation)     (None, 256, 256, 32) 0           batch_normalization_186[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_187 (BatchN (None, 256, 256, 32) 128         conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 256, 256, 32) 9248        activation_172[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_17 (Add)                    (None, 256, 256, 32) 0           batch_normalization_187[0][0]    \n",
      "                                                                 conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 256, 256, 1)  33          add_17[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 4,723,057\n",
      "Trainable params: 4,715,761\n",
      "Non-trainable params: 7,296\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "data_gen_args = dict(rotation_range=0.2,\n",
    "                    width_shift_range=0.05,\n",
    "                    height_shift_range=0.05,\n",
    "                    shear_range=0.05,\n",
    "                    zoom_range=0.05,\n",
    "                    horizontal_flip=True,\n",
    "                    fill_mode='nearest')\n",
    "myGene = trainGenerator(2,'./data/train','image','label',data_gen_args, save_to_dir = './data/train/aug')\n",
    "#model = unet()\n",
    "model = ResUNet()\n",
    "model_checkpoint = ModelCheckpoint('unet_membrane.hdf5', monitor='loss',verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "Found 196 images belonging to 1 classes.\n",
      "Found 196 images belonging to 1 classes.\n",
      "1999/2000 [============================>.] - ETA: 0s - loss: 0.0885 - acc: 0.9705\n",
      "Epoch 00001: loss improved from inf to 0.08849, saving model to unet_membrane.hdf5\n",
      "2000/2000 [==============================] - 245s 123ms/step - loss: 0.0885 - acc: 0.9705\n",
      "Epoch 2/10\n",
      "1999/2000 [============================>.] - ETA: 0s - loss: 0.0287 - acc: 0.9897\n",
      "Epoch 00002: loss improved from 0.08849 to 0.02874, saving model to unet_membrane.hdf5\n",
      "2000/2000 [==============================] - 215s 108ms/step - loss: 0.0287 - acc: 0.9897\n",
      "Epoch 3/10\n",
      "1999/2000 [============================>.] - ETA: 0s - loss: 0.0161 - acc: 0.9939\n",
      "Epoch 00003: loss improved from 0.02874 to 0.01611, saving model to unet_membrane.hdf5\n",
      "2000/2000 [==============================] - 216s 108ms/step - loss: 0.0161 - acc: 0.9939\n",
      "Epoch 4/10\n",
      "1999/2000 [============================>.] - ETA: 0s - loss: 0.0137 - acc: 0.9946\n",
      "Epoch 00004: loss improved from 0.01611 to 0.01375, saving model to unet_membrane.hdf5\n",
      "2000/2000 [==============================] - 221s 111ms/step - loss: 0.0137 - acc: 0.9946\n",
      "Epoch 5/10\n",
      "1999/2000 [============================>.] - ETA: 0s - loss: 0.0110 - acc: 0.9957\n",
      "Epoch 00005: loss improved from 0.01375 to 0.01100, saving model to unet_membrane.hdf5\n",
      "2000/2000 [==============================] - 224s 112ms/step - loss: 0.0110 - acc: 0.9957\n",
      "Epoch 6/10\n",
      "1999/2000 [============================>.] - ETA: 0s - loss: 0.0094 - acc: 0.9962\n",
      "Epoch 00006: loss improved from 0.01100 to 0.00939, saving model to unet_membrane.hdf5\n",
      "2000/2000 [==============================] - 227s 114ms/step - loss: 0.0094 - acc: 0.9962\n",
      "Epoch 7/10\n",
      "1999/2000 [============================>.] - ETA: 0s - loss: 0.0092 - acc: 0.9963\n",
      "Epoch 00007: loss improved from 0.00939 to 0.00920, saving model to unet_membrane.hdf5\n",
      "2000/2000 [==============================] - 230s 115ms/step - loss: 0.0092 - acc: 0.9963\n",
      "Epoch 8/10\n",
      "1999/2000 [============================>.] - ETA: 0s - loss: 0.0068 - acc: 0.9971\n",
      "Epoch 00008: loss improved from 0.00920 to 0.00683, saving model to unet_membrane.hdf5\n",
      "2000/2000 [==============================] - 231s 115ms/step - loss: 0.0068 - acc: 0.9971\n",
      "Epoch 9/10\n",
      "1999/2000 [============================>.] - ETA: 0s - loss: 0.0081 - acc: 0.9968\n",
      "Epoch 00009: loss did not improve from 0.00683\n",
      "2000/2000 [==============================] - 234s 117ms/step - loss: 0.0081 - acc: 0.9968\n",
      "Epoch 10/10\n",
      "1999/2000 [============================>.] - ETA: 0s - loss: 0.0074 - acc: 0.9971\n",
      "Epoch 00010: loss did not improve from 0.00683\n",
      "2000/2000 [==============================] - 236s 118ms/step - loss: 0.0074 - acc: 0.9971\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2965ba0e320>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "model.fit_generator(myGene,steps_per_epoch=2000,epochs=10,callbacks=[model_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testGenerator(test_path,num_image = 30,target_size = (256,256),flag_multi_class = False,as_gray = False):\n",
    "    for i in range(num_image):\n",
    "        img = io.imread(os.path.join(test_path,\"im{:02}.tif\".format(i)),as_gray = as_gray)\n",
    "        img = img / 255\n",
    "        img = trans.resize(img,target_size)\n",
    "        #img = np.reshape(img,img.shape+(1,)) if (not flag_multi_class) else img\n",
    "        img = np.reshape(img,(1,)+img.shape)\n",
    "        yield img\n",
    "        \n",
    "def saveResult(save_path,npyfile,flag_multi_class = False,num_class = 2):\n",
    "    for i,item in enumerate(npyfile):\n",
    "        img = labelVisualize(num_class,COLOR_DICT,item) if flag_multi_class else item[:,:,0]\n",
    "        io.imsave(os.path.join(save_path,\"%d_predict.jpg\"%i),img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_6 (InputLayer)            (None, 256, 256, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 256, 256, 16) 448         input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_188 (BatchN (None, 256, 256, 16) 64          conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_173 (Activation)     (None, 256, 256, 16) 0           batch_normalization_188[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 256, 256, 16) 64          input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 256, 256, 16) 2320        activation_173[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_189 (BatchN (None, 256, 256, 16) 64          conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_18 (Add)                    (None, 256, 256, 16) 0           conv2d_64[0][0]                  \n",
      "                                                                 batch_normalization_189[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_190 (BatchN (None, 256, 256, 16) 64          add_18[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_174 (Activation)     (None, 256, 256, 16) 0           batch_normalization_190[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 128, 128, 32) 4640        activation_174[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_191 (BatchN (None, 128, 128, 32) 128         conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 128, 128, 32) 544         add_18[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_175 (Activation)     (None, 128, 128, 32) 0           batch_normalization_191[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_192 (BatchN (None, 128, 128, 32) 128         conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 128, 128, 32) 9248        activation_175[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_19 (Add)                    (None, 128, 128, 32) 0           batch_normalization_192[0][0]    \n",
      "                                                                 conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_193 (BatchN (None, 128, 128, 32) 128         add_19[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_176 (Activation)     (None, 128, 128, 32) 0           batch_normalization_193[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 64, 64, 64)   18496       activation_176[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_194 (BatchN (None, 64, 64, 64)   256         conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 64, 64, 64)   2112        add_19[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_177 (Activation)     (None, 64, 64, 64)   0           batch_normalization_194[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_195 (BatchN (None, 64, 64, 64)   256         conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 64, 64, 64)   36928       activation_177[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_20 (Add)                    (None, 64, 64, 64)   0           batch_normalization_195[0][0]    \n",
      "                                                                 conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_196 (BatchN (None, 64, 64, 64)   256         add_20[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_178 (Activation)     (None, 64, 64, 64)   0           batch_normalization_196[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 32, 32, 128)  73856       activation_178[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_197 (BatchN (None, 32, 32, 128)  512         conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 32, 32, 128)  8320        add_20[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_179 (Activation)     (None, 32, 32, 128)  0           batch_normalization_197[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_198 (BatchN (None, 32, 32, 128)  512         conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 32, 32, 128)  147584      activation_179[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_21 (Add)                    (None, 32, 32, 128)  0           batch_normalization_198[0][0]    \n",
      "                                                                 conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_199 (BatchN (None, 32, 32, 128)  512         add_21[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_180 (Activation)     (None, 32, 32, 128)  0           batch_normalization_199[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 16, 16, 256)  295168      activation_180[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_200 (BatchN (None, 16, 16, 256)  1024        conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 16, 16, 256)  33024       add_21[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_181 (Activation)     (None, 16, 16, 256)  0           batch_normalization_200[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_201 (BatchN (None, 16, 16, 256)  1024        conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 16, 16, 256)  590080      activation_181[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_22 (Add)                    (None, 16, 16, 256)  0           batch_normalization_201[0][0]    \n",
      "                                                                 conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_202 (BatchN (None, 16, 16, 256)  1024        add_22[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_182 (Activation)     (None, 16, 16, 256)  0           batch_normalization_202[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 16, 16, 256)  590080      activation_182[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_203 (BatchN (None, 16, 16, 256)  1024        conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_183 (Activation)     (None, 16, 16, 256)  0           batch_normalization_203[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 16, 16, 256)  590080      activation_183[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_8 (UpSampling2D)  (None, 32, 32, 256)  0           conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_32 (Concatenate)    (None, 32, 32, 384)  0           up_sampling2d_8[0][0]            \n",
      "                                                                 add_21[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_204 (BatchN (None, 32, 32, 384)  1536        concatenate_32[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_184 (Activation)     (None, 32, 32, 384)  0           batch_normalization_204[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 32, 32, 256)  884992      activation_184[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_205 (BatchN (None, 32, 32, 256)  1024        conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 32, 32, 256)  98560       concatenate_32[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_185 (Activation)     (None, 32, 32, 256)  0           batch_normalization_205[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_206 (BatchN (None, 32, 32, 256)  1024        conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 32, 32, 256)  590080      activation_185[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_23 (Add)                    (None, 32, 32, 256)  0           batch_normalization_206[0][0]    \n",
      "                                                                 conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_9 (UpSampling2D)  (None, 64, 64, 256)  0           add_23[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_33 (Concatenate)    (None, 64, 64, 320)  0           up_sampling2d_9[0][0]            \n",
      "                                                                 add_20[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_207 (BatchN (None, 64, 64, 320)  1280        concatenate_33[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_186 (Activation)     (None, 64, 64, 320)  0           batch_normalization_207[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 64, 64, 128)  368768      activation_186[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_208 (BatchN (None, 64, 64, 128)  512         conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 64, 64, 128)  41088       concatenate_33[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_187 (Activation)     (None, 64, 64, 128)  0           batch_normalization_208[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_209 (BatchN (None, 64, 64, 128)  512         conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 64, 64, 128)  147584      activation_187[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_24 (Add)                    (None, 64, 64, 128)  0           batch_normalization_209[0][0]    \n",
      "                                                                 conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_10 (UpSampling2D) (None, 128, 128, 128 0           add_24[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_34 (Concatenate)    (None, 128, 128, 160 0           up_sampling2d_10[0][0]           \n",
      "                                                                 add_19[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_210 (BatchN (None, 128, 128, 160 640         concatenate_34[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_188 (Activation)     (None, 128, 128, 160 0           batch_normalization_210[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 128, 128, 64) 92224       activation_188[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_211 (BatchN (None, 128, 128, 64) 256         conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 128, 128, 64) 10304       concatenate_34[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_189 (Activation)     (None, 128, 128, 64) 0           batch_normalization_211[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_212 (BatchN (None, 128, 128, 64) 256         conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 128, 128, 64) 36928       activation_189[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_25 (Add)                    (None, 128, 128, 64) 0           batch_normalization_212[0][0]    \n",
      "                                                                 conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_11 (UpSampling2D) (None, 256, 256, 64) 0           add_25[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_35 (Concatenate)    (None, 256, 256, 80) 0           up_sampling2d_11[0][0]           \n",
      "                                                                 add_18[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_213 (BatchN (None, 256, 256, 80) 320         concatenate_35[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_190 (Activation)     (None, 256, 256, 80) 0           batch_normalization_213[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 256, 256, 32) 23072       activation_190[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_214 (BatchN (None, 256, 256, 32) 128         conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 256, 256, 32) 2592        concatenate_35[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_191 (Activation)     (None, 256, 256, 32) 0           batch_normalization_214[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_215 (BatchN (None, 256, 256, 32) 128         conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 256, 256, 32) 9248        activation_191[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_26 (Add)                    (None, 256, 256, 32) 0           batch_normalization_215[0][0]    \n",
      "                                                                 conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, 256, 256, 1)  33          add_26[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 4,723,057\n",
      "Trainable params: 4,715,761\n",
      "Non-trainable params: 7,296\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\skimage\\transform\\_warps.py:105: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 3s 90ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\skimage\\util\\dtype.py:130: UserWarning: Possible precision loss when converting from float32 to uint8\n",
      "  .format(dtypeobj_in, dtypeobj_out))\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\skimage\\io\\_io.py:140: UserWarning: ./data/test\\1_predict.jpg is a low contrast image\n",
      "  warn('%s is a low contrast image' % fname)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\skimage\\io\\_io.py:140: UserWarning: ./data/test\\2_predict.jpg is a low contrast image\n",
      "  warn('%s is a low contrast image' % fname)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\skimage\\io\\_io.py:140: UserWarning: ./data/test\\3_predict.jpg is a low contrast image\n",
      "  warn('%s is a low contrast image' % fname)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\skimage\\io\\_io.py:140: UserWarning: ./data/test\\4_predict.jpg is a low contrast image\n",
      "  warn('%s is a low contrast image' % fname)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\skimage\\io\\_io.py:140: UserWarning: ./data/test\\5_predict.jpg is a low contrast image\n",
      "  warn('%s is a low contrast image' % fname)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\skimage\\io\\_io.py:140: UserWarning: ./data/test\\6_predict.jpg is a low contrast image\n",
      "  warn('%s is a low contrast image' % fname)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\skimage\\io\\_io.py:140: UserWarning: ./data/test\\7_predict.jpg is a low contrast image\n",
      "  warn('%s is a low contrast image' % fname)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\skimage\\io\\_io.py:140: UserWarning: ./data/test\\8_predict.jpg is a low contrast image\n",
      "  warn('%s is a low contrast image' % fname)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\skimage\\io\\_io.py:140: UserWarning: ./data/test\\9_predict.jpg is a low contrast image\n",
      "  warn('%s is a low contrast image' % fname)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\skimage\\io\\_io.py:140: UserWarning: ./data/test\\10_predict.jpg is a low contrast image\n",
      "  warn('%s is a low contrast image' % fname)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\skimage\\io\\_io.py:140: UserWarning: ./data/test\\11_predict.jpg is a low contrast image\n",
      "  warn('%s is a low contrast image' % fname)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\skimage\\io\\_io.py:140: UserWarning: ./data/test\\12_predict.jpg is a low contrast image\n",
      "  warn('%s is a low contrast image' % fname)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\skimage\\io\\_io.py:140: UserWarning: ./data/test\\23_predict.jpg is a low contrast image\n",
      "  warn('%s is a low contrast image' % fname)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\skimage\\io\\_io.py:140: UserWarning: ./data/test\\24_predict.jpg is a low contrast image\n",
      "  warn('%s is a low contrast image' % fname)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\skimage\\io\\_io.py:140: UserWarning: ./data/test\\28_predict.jpg is a low contrast image\n",
      "  warn('%s is a low contrast image' % fname)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np \n",
    "import os\n",
    "import glob\n",
    "import skimage.io as io\n",
    "import skimage.transform as trans\n",
    "testGene = testGenerator(\"./data/test\")\n",
    "model = ResUNet()\n",
    "#model = unet()\n",
    "model.load_weights(\"unet_membrane.hdf5\")\n",
    "results = model.predict_generator(testGene,30,verbose=1)\n",
    "saveResult(\"./data/test\",results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 images belonging to 1 classes.\n",
      "Found 0 images belonging to 1 classes.\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 256, 256, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 128, 128, 3)  0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "octave_conv2d_46 (OctaveConv2D) [(None, 256, 256, 56 3456        input_3[0][0]                    \n",
      "                                                                 average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, 256, 256, 56) 224         octave_conv2d_46[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, 128, 128, 8)  32          octave_conv2d_46[0][1]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, 256, 256, 56) 0           batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, 128, 128, 8)  0           batch_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "octave_conv2d_47 (OctaveConv2D) [(None, 256, 256, 56 36864       activation_90[0][0]              \n",
      "                                                                 activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, 256, 256, 56) 224         octave_conv2d_47[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, 128, 128, 8)  32          octave_conv2d_47[0][1]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, 256, 256, 56) 0           batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, 128, 128, 8)  0           batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling2D) (None, 128, 128, 56) 0           activation_92[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling2D) (None, 64, 64, 8)    0           activation_93[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "octave_conv2d_48 (OctaveConv2D) [(None, 128, 128, 11 73728       max_pooling2d_16[0][0]           \n",
      "                                                                 max_pooling2d_17[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, 128, 128, 112 448         octave_conv2d_48[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, 64, 64, 16)   64          octave_conv2d_48[0][1]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_94 (Activation)      (None, 128, 128, 112 0           batch_normalization_92[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_95 (Activation)      (None, 64, 64, 16)   0           batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "octave_conv2d_49 (OctaveConv2D) [(None, 128, 128, 11 147456      activation_94[0][0]              \n",
      "                                                                 activation_95[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_94 (BatchNo (None, 128, 128, 112 448         octave_conv2d_49[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_95 (BatchNo (None, 64, 64, 16)   64          octave_conv2d_49[0][1]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_96 (Activation)      (None, 128, 128, 112 0           batch_normalization_94[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_97 (Activation)      (None, 64, 64, 16)   0           batch_normalization_95[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling2D) (None, 64, 64, 112)  0           activation_96[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_19 (MaxPooling2D) (None, 32, 32, 16)   0           activation_97[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "octave_conv2d_50 (OctaveConv2D) [(None, 64, 64, 224) 294912      max_pooling2d_18[0][0]           \n",
      "                                                                 max_pooling2d_19[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_96 (BatchNo (None, 64, 64, 224)  896         octave_conv2d_50[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_97 (BatchNo (None, 32, 32, 32)   128         octave_conv2d_50[0][1]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_98 (Activation)      (None, 64, 64, 224)  0           batch_normalization_96[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_99 (Activation)      (None, 32, 32, 32)   0           batch_normalization_97[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "octave_conv2d_51 (OctaveConv2D) [(None, 64, 64, 224) 589824      activation_98[0][0]              \n",
      "                                                                 activation_99[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_98 (BatchNo (None, 64, 64, 224)  896         octave_conv2d_51[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_99 (BatchNo (None, 32, 32, 32)   128         octave_conv2d_51[0][1]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_100 (Activation)     (None, 64, 64, 224)  0           batch_normalization_98[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_101 (Activation)     (None, 32, 32, 32)   0           batch_normalization_99[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling2D) (None, 32, 32, 224)  0           activation_100[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_21 (MaxPooling2D) (None, 16, 16, 32)   0           activation_101[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "octave_conv2d_52 (OctaveConv2D) [(None, 32, 32, 448) 1179648     max_pooling2d_20[0][0]           \n",
      "                                                                 max_pooling2d_21[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_100 (BatchN (None, 32, 32, 448)  1792        octave_conv2d_52[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_101 (BatchN (None, 16, 16, 64)   256         octave_conv2d_52[0][1]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_102 (Activation)     (None, 32, 32, 448)  0           batch_normalization_100[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_103 (Activation)     (None, 16, 16, 64)   0           batch_normalization_101[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "octave_conv2d_53 (OctaveConv2D) [(None, 32, 32, 448) 2359296     activation_102[0][0]             \n",
      "                                                                 activation_103[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_102 (BatchN (None, 32, 32, 448)  1792        octave_conv2d_53[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_103 (BatchN (None, 16, 16, 64)   256         octave_conv2d_53[0][1]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_104 (Activation)     (None, 32, 32, 448)  0           batch_normalization_102[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_105 (Activation)     (None, 16, 16, 64)   0           batch_normalization_103[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_22 (MaxPooling2D) (None, 16, 16, 448)  0           activation_104[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_23 (MaxPooling2D) (None, 8, 8, 64)     0           activation_105[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "octave_conv2d_54 (OctaveConv2D) [(None, 16, 16, 896) 4718592     max_pooling2d_22[0][0]           \n",
      "                                                                 max_pooling2d_23[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_104 (BatchN (None, 16, 16, 896)  3584        octave_conv2d_54[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_105 (BatchN (None, 8, 8, 128)    512         octave_conv2d_54[0][1]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_106 (Activation)     (None, 16, 16, 896)  0           batch_normalization_104[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_107 (Activation)     (None, 8, 8, 128)    0           batch_normalization_105[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 16, 16, 896)  0           activation_106[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 8, 8, 128)    0           activation_107[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "octave_conv2d_55 (OctaveConv2D) [(None, 16, 16, 896) 9437184     dropout_8[0][0]                  \n",
      "                                                                 dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_106 (BatchN (None, 16, 16, 896)  3584        octave_conv2d_55[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_107 (BatchN (None, 8, 8, 128)    512         octave_conv2d_55[0][1]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_108 (Activation)     (None, 16, 16, 896)  0           batch_normalization_106[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_109 (Activation)     (None, 8, 8, 128)    0           batch_normalization_107[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 16, 16, 896)  0           activation_108[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 8, 8, 128)    0           activation_109[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "octave_conv2d_56 (OctaveConv2D) [(None, 32, 32, 448) 4718592     dropout_10[0][0]                 \n",
      "                                                                 dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_108 (BatchN (None, 32, 32, 448)  1792        octave_conv2d_56[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_109 (BatchN (None, 16, 16, 64)   256         octave_conv2d_56[0][1]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_110 (Activation)     (None, 32, 32, 448)  0           batch_normalization_108[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_111 (Activation)     (None, 16, 16, 64)   0           batch_normalization_109[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_16 (Concatenate)    (None, 32, 32, 896)  0           activation_104[0][0]             \n",
      "                                                                 activation_110[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_17 (Concatenate)    (None, 16, 16, 128)  0           activation_105[0][0]             \n",
      "                                                                 activation_111[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "octave_conv2d_57 (OctaveConv2D) [(None, 32, 32, 448) 4718592     concatenate_16[0][0]             \n",
      "                                                                 concatenate_17[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_110 (BatchN (None, 32, 32, 448)  1792        octave_conv2d_57[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_111 (BatchN (None, 16, 16, 64)   256         octave_conv2d_57[0][1]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_112 (Activation)     (None, 32, 32, 448)  0           batch_normalization_110[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_113 (Activation)     (None, 16, 16, 64)   0           batch_normalization_111[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "octave_conv2d_58 (OctaveConv2D) [(None, 32, 32, 448) 2359296     activation_112[0][0]             \n",
      "                                                                 activation_113[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_112 (BatchN (None, 32, 32, 448)  1792        octave_conv2d_58[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_113 (BatchN (None, 16, 16, 64)   256         octave_conv2d_58[0][1]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_114 (Activation)     (None, 32, 32, 448)  0           batch_normalization_112[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_115 (Activation)     (None, 16, 16, 64)   0           batch_normalization_113[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "octave_conv2d_59 (OctaveConv2D) [(None, 64, 64, 224) 1179648     activation_114[0][0]             \n",
      "                                                                 activation_115[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_114 (BatchN (None, 64, 64, 224)  896         octave_conv2d_59[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_115 (BatchN (None, 32, 32, 32)   128         octave_conv2d_59[0][1]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_116 (Activation)     (None, 64, 64, 224)  0           batch_normalization_114[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_117 (Activation)     (None, 32, 32, 32)   0           batch_normalization_115[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_18 (Concatenate)    (None, 64, 64, 448)  0           activation_100[0][0]             \n",
      "                                                                 activation_116[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_19 (Concatenate)    (None, 32, 32, 64)   0           activation_101[0][0]             \n",
      "                                                                 activation_117[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "octave_conv2d_60 (OctaveConv2D) [(None, 64, 64, 224) 1179648     concatenate_18[0][0]             \n",
      "                                                                 concatenate_19[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_116 (BatchN (None, 64, 64, 224)  896         octave_conv2d_60[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_117 (BatchN (None, 32, 32, 32)   128         octave_conv2d_60[0][1]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_118 (Activation)     (None, 64, 64, 224)  0           batch_normalization_116[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_119 (Activation)     (None, 32, 32, 32)   0           batch_normalization_117[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "octave_conv2d_61 (OctaveConv2D) [(None, 64, 64, 224) 589824      activation_118[0][0]             \n",
      "                                                                 activation_119[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_118 (BatchN (None, 64, 64, 224)  896         octave_conv2d_61[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_119 (BatchN (None, 32, 32, 32)   128         octave_conv2d_61[0][1]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_120 (Activation)     (None, 64, 64, 224)  0           batch_normalization_118[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_121 (Activation)     (None, 32, 32, 32)   0           batch_normalization_119[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "octave_conv2d_62 (OctaveConv2D) [(None, 128, 128, 11 294912      activation_120[0][0]             \n",
      "                                                                 activation_121[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_120 (BatchN (None, 128, 128, 112 448         octave_conv2d_62[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_121 (BatchN (None, 64, 64, 16)   64          octave_conv2d_62[0][1]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_122 (Activation)     (None, 128, 128, 112 0           batch_normalization_120[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_123 (Activation)     (None, 64, 64, 16)   0           batch_normalization_121[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_20 (Concatenate)    (None, 128, 128, 224 0           activation_96[0][0]              \n",
      "                                                                 activation_122[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_21 (Concatenate)    (None, 64, 64, 32)   0           activation_97[0][0]              \n",
      "                                                                 activation_123[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "octave_conv2d_63 (OctaveConv2D) [(None, 128, 128, 11 294912      concatenate_20[0][0]             \n",
      "                                                                 concatenate_21[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_122 (BatchN (None, 128, 128, 112 448         octave_conv2d_63[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_123 (BatchN (None, 64, 64, 16)   64          octave_conv2d_63[0][1]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_124 (Activation)     (None, 128, 128, 112 0           batch_normalization_122[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_125 (Activation)     (None, 64, 64, 16)   0           batch_normalization_123[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "octave_conv2d_64 (OctaveConv2D) [(None, 128, 128, 11 147456      activation_124[0][0]             \n",
      "                                                                 activation_125[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_124 (BatchN (None, 128, 128, 112 448         octave_conv2d_64[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_125 (BatchN (None, 64, 64, 16)   64          octave_conv2d_64[0][1]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_126 (Activation)     (None, 128, 128, 112 0           batch_normalization_124[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_127 (Activation)     (None, 64, 64, 16)   0           batch_normalization_125[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "octave_conv2d_65 (OctaveConv2D) [(None, 256, 256, 56 73728       activation_126[0][0]             \n",
      "                                                                 activation_127[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_126 (BatchN (None, 256, 256, 56) 224         octave_conv2d_65[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_127 (BatchN (None, 128, 128, 8)  32          octave_conv2d_65[0][1]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_128 (Activation)     (None, 256, 256, 56) 0           batch_normalization_126[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_129 (Activation)     (None, 128, 128, 8)  0           batch_normalization_127[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_22 (Concatenate)    (None, 256, 256, 112 0           activation_92[0][0]              \n",
      "                                                                 activation_128[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_23 (Concatenate)    (None, 128, 128, 16) 0           activation_93[0][0]              \n",
      "                                                                 activation_129[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "octave_conv2d_66 (OctaveConv2D) [(None, 256, 256, 56 73728       concatenate_22[0][0]             \n",
      "                                                                 concatenate_23[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_128 (BatchN (None, 256, 256, 56) 224         octave_conv2d_66[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_129 (BatchN (None, 128, 128, 8)  32          octave_conv2d_66[0][1]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_130 (Activation)     (None, 256, 256, 56) 0           batch_normalization_128[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_131 (Activation)     (None, 128, 128, 8)  0           batch_normalization_129[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "octave_conv2d_67 (OctaveConv2D) [(None, 256, 256, 56 36864       activation_130[0][0]             \n",
      "                                                                 activation_131[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_130 (BatchN (None, 256, 256, 56) 224         octave_conv2d_67[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_131 (BatchN (None, 128, 128, 8)  32          octave_conv2d_67[0][1]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_132 (Activation)     (None, 256, 256, 56) 0           batch_normalization_130[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_133 (Activation)     (None, 128, 128, 8)  0           batch_normalization_131[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "octave_conv2d_68 (OctaveConv2D) (None, 256, 256, 32) 18432       activation_132[0][0]             \n",
      "                                                                 activation_133[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_134 (Activation)     (None, 256, 256, 32) 0           octave_conv2d_68[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 256, 256, 1)  33          activation_134[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 34,554,017\n",
      "Trainable params: 34,540,321\n",
      "Non-trainable params: 13,696\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/3\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "integer division or modulo by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-055b88f203db>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;31m#myGene = trainGenerator(2,'data/membrane/train','image','label',data_gen_args, save_to_dir = 'data/membrane/train/aug')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmodel_checkpoint\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m \u001b[0mmodel_checkpoint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mModelCheckpoint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'unet_membrane.hdf5'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmonitor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'loss'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msave_best_only\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1777\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1778\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1779\u001b[1;33m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1780\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1781\u001b[0m   def evaluate_generator(self,\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m    173\u001b[0m       \u001b[0mbatch_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    174\u001b[0m       \u001b[1;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 175\u001b[1;33m         \u001b[0mgenerator_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    176\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'__len__'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\data_utils.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    822\u001b[0m       \u001b[0msuccess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    823\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msuccess\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 824\u001b[1;33m         \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mreraise\u001b[1;34m(tp, value, tb)\u001b[0m\n\u001b[0;32m    691\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    692\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 693\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    694\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    695\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\data_utils.py\u001b[0m in \u001b[0;36m_data_generator_task\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    687\u001b[0m               \u001b[1;31m# => Serialize calls to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    688\u001b[0m               \u001b[1;31m# infinite iterator/generator's next() function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 689\u001b[1;33m               \u001b[0mgenerator_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_generator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    690\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgenerator_output\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    691\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\keras_preprocessing\\image.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1524\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1525\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1526\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1527\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1528\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_batches_of_transformed_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex_array\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\keras_preprocessing\\image.py\u001b[0m in \u001b[0;36mnext\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1965\u001b[0m         \"\"\"\n\u001b[0;32m   1966\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1967\u001b[1;33m             \u001b[0mindex_array\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex_generator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1968\u001b[0m         \u001b[1;31m# The transformation of images is not under thread lock\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1969\u001b[0m         \u001b[1;31m# so it can be done in parallel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\keras_preprocessing\\image.py\u001b[0m in \u001b[0;36m_flow_index\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1509\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_index_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1510\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1511\u001b[1;33m             \u001b[0mcurrent_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_index\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1512\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mcurrent_index\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1513\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_index\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mZeroDivisionError\u001b[0m: integer division or modulo by zero"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "#step1 \n",
    "data_gen_args = dict(rotation_range=90.,\n",
    "                width_shift_range=0.05,\n",
    "                height_shift_range=0.05,\n",
    "                shear_range=0.05,\n",
    "                zoom_range=0.05,\n",
    "                horizontal_flip=True,\n",
    "                fill_mode='bicubic')\n",
    "\n",
    "image_datagen = ImageDataGenerator(**data_gen_args)\n",
    "mask_datagen = ImageDataGenerator(**data_gen_args)\n",
    "\n",
    "#step2\n",
    "seed = 1\n",
    "#image_datagen.fit(image, augment=True, seed=seed)\n",
    "#mask_datagen.fit(masks, augment=True, seed=seed)\n",
    "\n",
    "image_generator = image_datagen.flow_from_directory(\n",
    "'data/membrane/train',classes=['image'],target_size=(256,256),\n",
    "class_mode=None,color_mode=\"rgb\",batch_size=5)\n",
    "\n",
    "mask_generator = mask_datagen.flow_from_directory(\n",
    "'data/membrane/train',classes=['label'],target_size=(256,256),\n",
    "class_mode=None,color_mode=\"rgb\",batch_size=5)\n",
    "\n",
    "#step3\n",
    "train_generator = zip(image_generator, mask_generator)\n",
    "#train_generator = (pair for pair in zip(image_generator, mask_generator))\n",
    "\n",
    "#ディレクトリから画像を読み込む処理\n",
    "#myGene = trainGenerator(2,'data/membrane/train','image','label',data_gen_args, save_to_dir = 'data/membrane/train/aug')\n",
    "model = unet()\n",
    "model.fit_generator(train_generator,steps_per_epoch=100,epochs=3,callbacks=[model_checkpoint])\n",
    "model_checkpoint = keras.callbacks.ModelCheckpoint('unet_membrane.hdf5', monitor='loss',verbose=1, save_best_only=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testGenerator(test_path,num_image = 80,target_size = (256,256),flag_multi_class=True,as_gray=False):\n",
    "    filenames = os.listdir(test_path)\n",
    "    for filename in filenames:\n",
    "        img = io.imread(os.path.join(test_path,filename),as_gray=as_gray)\n",
    "        # img = img/255.\n",
    "        #img = trans.resize(img,target_size,mode = 'constant')\n",
    "        #img = np.reshape(img,img.shape+(1,)) if (not flag_multi_class) else img\n",
    "        img = np.reshape(img,(1,)+img.shape)\n",
    "        yield img\n",
    "        \n",
    "def saveResult(save_path,npyfile,flag_multi_class = True,num_class = 2):\n",
    "    for i,item in enumerate(npyfile):\n",
    "        img = item\n",
    "        img_out = np.zeros(img[:, :, 0].shape + (3,))\n",
    "        for row in range(img.shape[0]):\n",
    "            for col in range(img.shape[1]):\n",
    "                index_of_class = np.argmax(img[row, col])\n",
    "                img_out[row, col] = COLOR_DICT[index_of_class]\n",
    "        img = img_out.astype(np.uint8)\n",
    "        #img = labelVisualize(num_class,COLOR_DICT,item) if flag_multi_class else item[:,:,0]\n",
    "        io.imsave(os.path.join(save_path,\"%d_predict.png\"%i),img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np \n",
    "import os\n",
    "import glob\n",
    "import skimage.io as io\n",
    "import skimage.transform as trans\n",
    "testGene = testGenerator(\"data/membrane/test\")\n",
    "model = unet()\n",
    "model.load_weights(\"unet_membrane.hdf5\")\n",
    "results = model.predict_generator(testGene,80,verbose=1)\n",
    "saveResult(\"data/membrane/test\",results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#covert RGB to grayscale\n",
    "import cv2\n",
    "\n",
    "import os,glob\n",
    "\n",
    "from os import listdir,makedirs\n",
    "\n",
    "from os.path import isfile,join\n",
    "path = 'data/membrane/train/label' # Source Folder\n",
    "dstpath = 'data/membrane/train/label' # Destination Folder\n",
    "try:\n",
    "    makedirs(dstpath)\n",
    "except:\n",
    "    print (\"Directory already exist, images will be written in same folder\")\n",
    "# Folder won't used\n",
    "files = [f for f in listdir(path) if isfile(join(path,f))] \n",
    "for image in files:\n",
    "    try:\n",
    "        img = cv2.imread(os.path.join(path,image))\n",
    "        gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "        dstPath = join(dstpath,image)\n",
    "        cv2.imwrite(dstPath,gray)\n",
    "    except:\n",
    "        print (\"{} is not converted\".format(image))\n",
    "for fil in glob.glob(\"*.png\"):\n",
    "    try:\n",
    "        image = cv2.imread(fil) \n",
    "        gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) # convert to greyscale\n",
    "        cv2.imwrite(os.path.join(dstpath,fil),gray_image)\n",
    "    except:\n",
    "        print('{} is not converted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "import os,glob\n",
    "\n",
    "from os.path import isfile,join\n",
    "\n",
    "path = 'data/membrane/test_b' # Source Folder\n",
    "dstpath = 'data/membrane/test_b' # Destination Folder\n",
    "try:\n",
    "    makedirs(dstpath)\n",
    "except:\n",
    "    print (\"Directory already exist, images will be written in same folder\")\n",
    "# Folder won't used\n",
    "files = [f for f in listdir(path) if isfile(join(path,f))] \n",
    "for image in files:\n",
    "    try:\n",
    "        img = cv2.imread(os.path.join(path,image))\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "        invgray = cv2.bitwise_not(gray)\n",
    "        dstPath = join(dstpath,image)\n",
    "        cv2.imwrite(dstPath,invgray)\n",
    "    except:\n",
    "        print (\"{} is not converted\".format(image))\n",
    "\"\"\"\n",
    "for fil in glob.glob(\"*.jpg\"):\n",
    "    try:\n",
    "        image = cv2.imread(fil) \n",
    "        gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) # convert to greyscale\n",
    "        gray_image = cv2.bitwise_not(gray_image)\n",
    "        cv2.imwrite(os.path.join(dstpath,fil),gray_image)\n",
    "    except:\n",
    "        print('{} is not converted')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "import os,glob\n",
    "\n",
    "from os.path import isfile,join\n",
    "target_size = (256,256)\n",
    "\n",
    "path = 'data/membrane/train/label' # Source Folder\n",
    "dstpath = 'data/membrane/train/label' # Destination Folder\n",
    "\n",
    "try:\n",
    "    makedirs(dstpath)\n",
    "except:\n",
    "    print (\"Directory already exist, images will be written in same folder\")\n",
    "# Folder won't used\n",
    "files = [f for f in listdir(path) if isfile(join(path,f))] \n",
    "for image in files:\n",
    "    try:\n",
    "        img = cv2.imread(os.path.join(path,image))\n",
    "        img = cv2.resize(img,target_size)\n",
    "        dstPath = join(dstpath,image)\n",
    "        cv2.imwrite(dstPath,img)\n",
    "    except:\n",
    "        print (\"{} is not converted\".format(image))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
